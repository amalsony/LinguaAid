# LinguaAid - Live Translation App for First Aid Workers & Refugees

LinguaAid is a real-time translation application designed specifically for first aid field workers and refugees to communicate effectively during emergency situations. The app provides instant speech-to-speech translation with automatic transcription and form filling capabilities.

## ğŸŒŸ Features

- **Split-Screen Interface**: Separate sides for refugee/patient and responder
- **Real-Time Speech Translation**: 
  - Press and hold to record speech
  - Automatic transcription using ElevenLabs API
  - Translation powered by Google Gemini AI
  - Text-to-speech playback of translations
- **Conversation Transcript**: Download complete conversation history
- **Automatic Form Filling**: AI-powered extraction of patient information (name, age, medical conditions, allergies, etc.)
- **Multi-Language Support**: English, Arabic, Farsi, Pashto, Spanish, French, Somali, Swahili, Ukrainian, Tigrinya
- **Accessible Design**: High contrast, large touch targets, and responsive layout

## ğŸš€ Getting Started

### Prerequisites

- Node.js 18+ 
- npm or yarn
- ElevenLabs API key ([Get one here](https://elevenlabs.io/))
- Google Gemini API key ([Get one here](https://makersuite.google.com/app/apikey))

### Installation

1. **Clone the repository**
   ```bash
   cd LinguaAid-Frontend
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Configure environment variables**
   - Copy `.env.example` to `.env.local`
   ```bash
   copy .env.example .env.local
   ```
   - Edit `.env.local` and add your API keys:
   ```
   ELEVENLABS_API_KEY=your_actual_elevenlabs_key
   GEMINI_API_KEY=your_actual_gemini_key
   ```

4. **Run the development server**
   ```bash
   npm run dev
   ```

5. **Open your browser**
   - Navigate to [http://localhost:3000](http://localhost:3000)

## ğŸ“± How to Use

### Starting a Translation Session

1. Click "Start Live Translation" or navigate to `/talk`
2. **Refugee/Patient side** (left, blue):
   - Select their language from the dropdown
   - Press the microphone button to speak
   - Release to process the audio
3. **Responder side** (right, green):
   - Select their language (default: English)
   - Press the microphone button to speak
   - Release to process the audio

### Features During Session

- **Auto-play translations**: Toggle to automatically play translated text as speech
- **View Transcript**: See the full conversation history
- **Download Transcript**: Save conversation as a text file
- **Extract Patient Info**: Use AI to automatically extract and structure patient information from the conversation

## ğŸ—ï¸ Project Structure

```
LinguaAid-Frontend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                    # Next.js API routes
â”‚   â”‚   â”œâ”€â”€ transcribe/        # ElevenLabs speech-to-text
â”‚   â”‚   â”œâ”€â”€ translate/         # Gemini translation
â”‚   â”‚   â”œâ”€â”€ text-to-speech/    # ElevenLabs text-to-speech
â”‚   â”‚   â””â”€â”€ extract-info/      # Gemini info extraction
â”‚   â”œâ”€â”€ talk/                  # Main translation interface
â”‚   â”œâ”€â”€ dashboard/             # Statistics and info
â”‚   â”œâ”€â”€ layout.tsx             # Root layout
â”‚   â”œâ”€â”€ page.tsx               # Home page
â”‚   â””â”€â”€ globals.css            # Global styles
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ SplitScreenTranslator.tsx  # Main translation component
â”‚   â”œâ”€â”€ NavBar.tsx
â”‚   â”œâ”€â”€ Logo.tsx
â”‚   â”œâ”€â”€ ThemeToggle.tsx
â”‚   â”œâ”€â”€ AccessibilityButton.tsx
â”‚   â”œâ”€â”€ A11yProvider.tsx
â”‚   â””â”€â”€ PageTabs.tsx
â””â”€â”€ public/                    # Static assets
```

## ğŸ”§ API Endpoints

### POST `/api/transcribe`
- **Purpose**: Convert audio to text
- **Input**: FormData with audio file
- **Output**: `{ transcription: string }`

### POST `/api/translate`
- **Purpose**: Translate text between languages
- **Input**: `{ text, sourceLang, targetLang }`
- **Output**: `{ translation: string }`

### POST `/api/text-to-speech`
- **Purpose**: Convert text to speech audio
- **Input**: `{ text, voiceId? }`
- **Output**: Audio stream (audio/mpeg)

### POST `/api/extract-info`
- **Purpose**: Extract patient information from conversation
- **Input**: `{ transcript }`
- **Output**: `{ data: PatientInfo }`

## ğŸŒ Supported Languages

- English (en)
- Arabic (ar)
- French (fr)
- Spanish (es)
- Farsi/Persian (fa)
- Pashto (ps)
- Ukrainian (uk)
- Somali (so)
- Tigrinya (ti)
- Swahili (sw)

## ğŸ› ï¸ Technologies Used

- **Framework**: Next.js 16 (App Router)
- **Language**: TypeScript
- **Styling**: Tailwind CSS
- **Speech-to-Text**: ElevenLabs API
- **Text-to-Speech**: ElevenLabs API
- **Translation & AI**: Google Gemini API
- **Audio Recording**: MediaRecorder API (Web API)

## ğŸ“ Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `ELEVENLABS_API_KEY` | API key for ElevenLabs (transcription & TTS) | Yes |
| `GEMINI_API_KEY` | API key for Google Gemini (translation & extraction) | Yes |

## ğŸš¢ Deployment

### Build for Production

```bash
npm run build
npm start
```

### Deploy to Vercel (Recommended)

1. Push your code to GitHub
2. Import project to Vercel
3. Add environment variables in Vercel dashboard
4. Deploy

## ğŸ¤ Contributing

This is a hackathon project. Contributions and improvements are welcome!

## ğŸ“„ License

MIT License - feel free to use this project for your needs.

## ğŸ™ Acknowledgments

- ElevenLabs for high-quality speech services
- Google Gemini for powerful AI translation
- First aid workers and humanitarian organizations worldwide

## ğŸ“ Support

For issues or questions, please open an issue on GitHub.

---

Built with â¤ï¸ for humanitarian aid workers and refugees worldwide.

